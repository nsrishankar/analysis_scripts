{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Analysis-Scripts-for-Cluster-Data\" data-toc-modified-id=\"Analysis-Scripts-for-Cluster-Data-0\"><span class=\"toc-item-num\">0&nbsp;&nbsp;</span>Analysis Scripts for Cluster Data</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Dictionary-Creation\" data-toc-modified-id=\"Dictionary-Creation-0.0.1\"><span class=\"toc-item-num\">0.0.1&nbsp;&nbsp;</span>Dictionary Creation</a></span></li></ul></li></ul></li><li><span><a href=\"#Converged-Experiments-with-0%-sensor-noise\" data-toc-modified-id=\"Converged-Experiments-with-0%-sensor-noise-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Converged Experiments with 0% sensor noise</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Dictionary-Creation-for-successful-seeds-with-0-%-sensor-noise\" data-toc-modified-id=\"Dictionary-Creation-for-successful-seeds-with-0-%-sensor-noise-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Dictionary Creation for successful seeds with 0 % sensor noise</a></span></li><li><span><a href=\"#Dictionaries-for-timestep-and-density-ratios\" data-toc-modified-id=\"Dictionaries-for-timestep-and-density-ratios-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Dictionaries for timestep and density ratios</a></span></li></ul></li><li><span><a href=\"#Boxplot-Time-to-converge-vs.-Working-robot-ratio\" data-toc-modified-id=\"Boxplot-Time-to-converge-vs.-Working-robot-ratio-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Boxplot Time to converge vs. Working robot ratio</a></span></li><li><span><a href=\"#Boxplot-Time-to-converge-vs.-Density\" data-toc-modified-id=\"Boxplot-Time-to-converge-vs.-Density-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Boxplot Time to converge vs. Density</a></span></li></ul></li><li><span><a href=\"#Converged-Experiments-with-10%-sensor-noise\" data-toc-modified-id=\"Converged-Experiments-with-10%-sensor-noise-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Converged Experiments with 10% sensor noise</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Dictionary-Creation-for-successful-seeds-with-10-%-sensor-noise\" data-toc-modified-id=\"Dictionary-Creation-for-successful-seeds-with-10-%-sensor-noise-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>Dictionary Creation for successful seeds with 10 % sensor noise</a></span></li><li><span><a href=\"#Dictionaries-for-timestep-and-density-ratios\" data-toc-modified-id=\"Dictionaries-for-timestep-and-density-ratios-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>Dictionaries for timestep and density ratios</a></span></li></ul></li><li><span><a href=\"#Boxplot-Time-to-converge-vs.-Working-robot-ratio\" data-toc-modified-id=\"Boxplot-Time-to-converge-vs.-Working-robot-ratio-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Boxplot Time to converge vs. Working robot ratio</a></span></li><li><span><a href=\"#Boxplot-Time-to-converge-vs.-Density\" data-toc-modified-id=\"Boxplot-Time-to-converge-vs.-Density-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Boxplot Time to converge vs. Density</a></span></li></ul></li><li><span><a href=\"#Converged-Experiments-with-20%-sensor-noise\" data-toc-modified-id=\"Converged-Experiments-with-20%-sensor-noise-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Converged Experiments with 20% sensor noise</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Dictionary-Creation-for-successful-seeds-with-20-%-sensor-noise\" data-toc-modified-id=\"Dictionary-Creation-for-successful-seeds-with-20-%-sensor-noise-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Dictionary Creation for successful seeds with 20 % sensor noise</a></span></li><li><span><a href=\"#Dictionaries-for-timestep-and-density-ratios\" data-toc-modified-id=\"Dictionaries-for-timestep-and-density-ratios-3.0.2\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>Dictionaries for timestep and density ratios</a></span></li></ul></li><li><span><a href=\"#Boxplot-Time-to-converge-vs.-Working-robot-ratio\" data-toc-modified-id=\"Boxplot-Time-to-converge-vs.-Working-robot-ratio-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Boxplot Time to converge vs. Working robot ratio</a></span></li><li><span><a href=\"#Boxplot-Time-to-converge-vs.-Density\" data-toc-modified-id=\"Boxplot-Time-to-converge-vs.-Density-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Boxplot Time to converge vs. Density</a></span></li></ul></li><li><span><a href=\"#Converged-Experiments-with-40%-sensor-noise\" data-toc-modified-id=\"Converged-Experiments-with-40%-sensor-noise-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Converged Experiments with 40% sensor noise</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Dictionary-Creation-for-successful-seeds-with-40-%-sensor-noise\" data-toc-modified-id=\"Dictionary-Creation-for-successful-seeds-with-40-%-sensor-noise-4.0.1\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span>Dictionary Creation for successful seeds with 40 % sensor noise</a></span></li><li><span><a href=\"#Dictionaries-for-timestep-and-density-ratios\" data-toc-modified-id=\"Dictionaries-for-timestep-and-density-ratios-4.0.2\"><span class=\"toc-item-num\">4.0.2&nbsp;&nbsp;</span>Dictionaries for timestep and density ratios</a></span></li></ul></li><li><span><a href=\"#Boxplot-Time-to-converge-vs.-Working-robot-ratio\" data-toc-modified-id=\"Boxplot-Time-to-converge-vs.-Working-robot-ratio-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Boxplot Time to converge vs. Working robot ratio</a></span></li><li><span><a href=\"#Boxplot-Time-to-converge-vs.-Density\" data-toc-modified-id=\"Boxplot-Time-to-converge-vs.-Density-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Boxplot Time to converge vs. Density</a></span></li></ul></li><li><span><a href=\"#Heatmap-Successful-Experiments\" data-toc-modified-id=\"Heatmap-Successful-Experiments-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Heatmap Successful Experiments</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Dictionary-Creation-for-all-successful-seeds-separated-by-sensor-noise\" data-toc-modified-id=\"Dictionary-Creation-for-all-successful-seeds-separated-by-sensor-noise-5.0.1\"><span class=\"toc-item-num\">5.0.1&nbsp;&nbsp;</span>Dictionary Creation for all successful seeds separated by sensor noise</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pandas-Count-of-successful-experiments\" data-toc-modified-id=\"Pandas-Count-of-successful-experiments-5.0.1.1\"><span class=\"toc-item-num\">5.0.1.1&nbsp;&nbsp;</span>Pandas Count of successful experiments</a></span></li><li><span><a href=\"#Pandas-Mean-timestep-for-successful-experiments\" data-toc-modified-id=\"Pandas-Mean-timestep-for-successful-experiments-5.0.1.2\"><span class=\"toc-item-num\">5.0.1.2&nbsp;&nbsp;</span>Pandas Mean timestep for successful experiments</a></span></li></ul></li></ul></li><li><span><a href=\"#Heatmap-Number-of-Successful-Experiments-[Sensor-Noise-vs.-Defecting-Ratio]\" data-toc-modified-id=\"Heatmap-Number-of-Successful-Experiments-[Sensor-Noise-vs.-Defecting-Ratio]-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Heatmap Number of Successful Experiments [Sensor Noise vs. Defecting Ratio]</a></span></li><li><span><a href=\"#Heatmap-Timestep-of-Successful-Experiments-[Sensor-Noise-vs.-Defecting-Ratio]\" data-toc-modified-id=\"Heatmap-Timestep-of-Successful-Experiments-[Sensor-Noise-vs.-Defecting-Ratio]-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Heatmap Timestep of Successful Experiments [Sensor Noise vs. Defecting Ratio]</a></span></li></ul></li><li><span><a href=\"#Heatmap-Failed-Experiments\" data-toc-modified-id=\"Heatmap-Failed-Experiments-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Heatmap Failed Experiments</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Dictionary-Creation-for-all-failed-seeds-separated-by-sensor-noise\" data-toc-modified-id=\"Dictionary-Creation-for-all-failed-seeds-separated-by-sensor-noise-6.0.1\"><span class=\"toc-item-num\">6.0.1&nbsp;&nbsp;</span>Dictionary Creation for all failed seeds separated by sensor noise</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pandas-Count-of-failed-experiments\" data-toc-modified-id=\"Pandas-Count-of-failed-experiments-6.0.1.1\"><span class=\"toc-item-num\">6.0.1.1&nbsp;&nbsp;</span>Pandas Count of failed experiments</a></span></li><li><span><a href=\"#Pandas-Mean-timestep-for-failed-experiments\" data-toc-modified-id=\"Pandas-Mean-timestep-for-failed-experiments-6.0.1.2\"><span class=\"toc-item-num\">6.0.1.2&nbsp;&nbsp;</span>Pandas Mean timestep for failed experiments</a></span></li></ul></li><li><span><a href=\"#Dictionary-Creation-for-counts-of-failed-robots\" data-toc-modified-id=\"Dictionary-Creation-for-counts-of-failed-robots-6.0.2\"><span class=\"toc-item-num\">6.0.2&nbsp;&nbsp;</span>Dictionary Creation for counts of failed robots</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pandas-Count-of-failed-robots-vs.-ratio-of-robots\" data-toc-modified-id=\"Pandas-Count-of-failed-robots-vs.-ratio-of-robots-6.0.2.1\"><span class=\"toc-item-num\">6.0.2.1&nbsp;&nbsp;</span>Pandas Count of failed robots vs. ratio of robots</a></span></li><li><span><a href=\"#Pandas-Count-of-failed-robots-vs.-number-of-working-robots\" data-toc-modified-id=\"Pandas-Count-of-failed-robots-vs.-number-of-working-robots-6.0.2.2\"><span class=\"toc-item-num\">6.0.2.2&nbsp;&nbsp;</span>Pandas Count of failed robots vs. number of working robots</a></span></li></ul></li></ul></li><li><span><a href=\"#Heatmap-Number-of-Failed-Experiments-[Sensor-Noise-vs.-Defecting-Ratio]\" data-toc-modified-id=\"Heatmap-Number-of-Failed-Experiments-[Sensor-Noise-vs.-Defecting-Ratio]-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Heatmap Number of Failed Experiments [Sensor Noise vs. Defecting Ratio]</a></span></li><li><span><a href=\"#Heatmap-Timestep-of-Failed-Experiments-[Sensor-Noise-vs.-Defecting-Ratio]\" data-toc-modified-id=\"Heatmap-Timestep-of-Failed-Experiments-[Sensor-Noise-vs.-Defecting-Ratio]-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Heatmap Timestep of Failed Experiments [Sensor Noise vs. Defecting Ratio]</a></span></li><li><span><a href=\"#Heatmap-Number-of-Failed-Robots-[Sensor-Noise-vs.-Defecting-Ratio]\" data-toc-modified-id=\"Heatmap-Number-of-Failed-Robots-[Sensor-Noise-vs.-Defecting-Ratio]-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Heatmap Number of Failed Robots [Sensor Noise vs. Defecting Ratio]</a></span></li><li><span><a href=\"#Heatmap-Number-of-Failed-Robots-[Sensor-Noise-vs.-Working-Robots]\" data-toc-modified-id=\"Heatmap-Number-of-Failed-Robots-[Sensor-Noise-vs.-Working-Robots]-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Heatmap Number of Failed Robots [Sensor Noise vs. Working Robots]</a></span></li></ul></li><li><span><a href=\"#Scatter-Plot-of-Messages-Listened/Ignored\" data-toc-modified-id=\"Scatter-Plot-of-Messages-Listened/Ignored-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Scatter Plot of Messages Listened/Ignored</a></span><ul class=\"toc-item\"><li><span><a href=\"#Successful-experiments\" data-toc-modified-id=\"Successful-experiments-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Successful experiments</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dictionaries-for-message-counts-and-final-beliefs\" data-toc-modified-id=\"Dictionaries-for-message-counts-and-final-beliefs-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>Dictionaries for message counts and final beliefs</a></span></li><li><span><a href=\"#Scatter-plot-messages-vs.-num.-robots\" data-toc-modified-id=\"Scatter-plot-messages-vs.-num.-robots-7.1.2\"><span class=\"toc-item-num\">7.1.2&nbsp;&nbsp;</span>Scatter plot messages vs. num. robots</a></span></li><li><span><a href=\"#Scatter-plot-messages-vs.-working-robot-ratio\" data-toc-modified-id=\"Scatter-plot-messages-vs.-working-robot-ratio-7.1.3\"><span class=\"toc-item-num\">7.1.3&nbsp;&nbsp;</span>Scatter plot messages vs. working robot ratio</a></span></li><li><span><a href=\"#Scatter-plot-beliefs-vs.-num.-robots\" data-toc-modified-id=\"Scatter-plot-beliefs-vs.-num.-robots-7.1.4\"><span class=\"toc-item-num\">7.1.4&nbsp;&nbsp;</span>Scatter plot beliefs vs. num. robots</a></span></li><li><span><a href=\"#Scatter-plot-beliefs-vs.-working-robot-ratio\" data-toc-modified-id=\"Scatter-plot-beliefs-vs.-working-robot-ratio-7.1.5\"><span class=\"toc-item-num\">7.1.5&nbsp;&nbsp;</span>Scatter plot beliefs vs. working robot ratio</a></span></li></ul></li><li><span><a href=\"#Failed-experiments\" data-toc-modified-id=\"Failed-experiments-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Failed experiments</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dictionaries-for-message-counts-and-final-beliefs\" data-toc-modified-id=\"Dictionaries-for-message-counts-and-final-beliefs-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>Dictionaries for message counts and final beliefs</a></span></li><li><span><a href=\"#Scatter-plot-messages-vs.-num.-robots\" data-toc-modified-id=\"Scatter-plot-messages-vs.-num.-robots-7.2.2\"><span class=\"toc-item-num\">7.2.2&nbsp;&nbsp;</span>Scatter plot messages vs. num. robots</a></span></li><li><span><a href=\"#Scatter-plot-messages-vs.-working-robot-ratio\" data-toc-modified-id=\"Scatter-plot-messages-vs.-working-robot-ratio-7.2.3\"><span class=\"toc-item-num\">7.2.3&nbsp;&nbsp;</span>Scatter plot messages vs. working robot ratio</a></span></li><li><span><a href=\"#Scatter-plot-beliefs-vs.-num.-robots\" data-toc-modified-id=\"Scatter-plot-beliefs-vs.-num.-robots-7.2.4\"><span class=\"toc-item-num\">7.2.4&nbsp;&nbsp;</span>Scatter plot beliefs vs. num. robots</a></span></li><li><span><a href=\"#Scatter-plot-beliefs-vs.-working-robot-ratio\" data-toc-modified-id=\"Scatter-plot-beliefs-vs.-working-robot-ratio-7.2.5\"><span class=\"toc-item-num\">7.2.5&nbsp;&nbsp;</span>Scatter plot beliefs vs. working robot ratio</a></span></li></ul></li></ul></li><li><span><a href=\"#BREAK\" data-toc-modified-id=\"BREAK-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>BREAK</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Analysis Scripts for Cluster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "import collections\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.pyplot import cm \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Dictionary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Nifty trick\n",
    "class Customdictionary(dict):\n",
    "    def __setitem__(self,key,value):\n",
    "        try:\n",
    "            self[key]\n",
    "        except KeyError:\n",
    "            super(Customdictionary,self).__setitem__(key,[])\n",
    "        self[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def keys_exists(element, *keys):\n",
    "    '''\n",
    "    Check if *keys (nested) exists in `element` (dict).\n",
    "    '''\n",
    "    _element = element\n",
    "    for key in keys:\n",
    "        try:\n",
    "            _element = _element[key]\n",
    "        except KeyError:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def remove_chars(string):\n",
    "    chars=\"[^0123456789\\.]\"\n",
    "    return re.sub(chars,\"\",string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Time [0],#Robot [1],#X [2],#Y [3]\n",
    "#PickedPatternNum [4],#PickedPattern [5] --> PATTERNPICKED\n",
    "#PickedPatternProb [6] -->PICKEDPROBABILITY\n",
    "#CorrectPatternProb [7] -->CORRECTPATTERNPROBABILITY\n",
    "#TotalReceivedMessages [8] -->NUMBEROFRECEIVEDMESSAGES\n",
    "#TotalPrunedMessages [9] -->NUMBEROFLISTENEDMESSAGES\n",
    "#TotalLyingMessages [10] -->NUMBEROFLYINGMESSAGESOBTAINED\n",
    "#TotalLyingMessagesBelieved [11] -->NUMBEROFLYINGMESSAGESLISTENED\n",
    "#CurrentThreshold [12] -->ROBOTTHRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pickle_dictionary=collections.defaultdict(dict)\n",
    "\n",
    "pickle_location='../cluster_data/motion_threshold_1212/'\n",
    "\n",
    "pickle_files=os.listdir(pickle_location)\n",
    "\n",
    "for i,pkl_file in enumerate(pickle_files):\n",
    "#         print(pkl_file,\"\\n\")\n",
    "        fname=pkl_file.split(\"_\")\n",
    "        \n",
    "        num_robots=remove_chars(fname[0])\n",
    "        num_liars=remove_chars(fname[1])\n",
    "        noise=remove_chars(fname[2])\n",
    "        density=remove_chars(fname[3])\n",
    "        seed=remove_chars(fname[4].split(\".\")[0])\n",
    "        \n",
    "        key_0=\"nrobots{}_nliars{}_noise{}_density{}\".format(num_robots,num_liars,noise,density)\n",
    "        key_1=\"seed{}\".format(seed)\n",
    "\n",
    "        data_path=os.path.join(pickle_location,pkl_file)\n",
    "        \n",
    "        if os.path.getsize(data_path)>0:      \n",
    "            with open(data_path,\"rb\") as f:\n",
    "                unpickler=pickle.Unpickler(f)\n",
    "                data=unpickler.load()\n",
    "                for k,v in data.items():\n",
    "                    pickle_dictionary[key_0][key_1]=v\n",
    "        else:\n",
    "            print(\"ISSUE: \", pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_seeds=[]\n",
    "failed_seeds=[]\n",
    "\n",
    "countfailed_robots_failedexp=Customdictionary()\n",
    "\n",
    "for k1,v1 in pickle_dictionary.items():\n",
    "    fname=k1.split(\"_\")\n",
    "    num_robots=int(remove_chars(fname[0]))\n",
    "    num_liars=int(remove_chars(fname[1]))\n",
    "    noise=float(remove_chars(fname[2]))\n",
    "    density=float(remove_chars(fname[3]))\n",
    "    num_working=num_robots-num_liars\n",
    "    \n",
    "    for k2,v2 in v1.items():\n",
    "        data_length=len(v2)\n",
    "        if (num_working==data_length):\n",
    "            successful_seeds.append(\"_\".join((k1,k2)))\n",
    "        elif (num_working>data_length):\n",
    "            failed_seeds.append(\"_\".join((k1,k2)))\n",
    "            failed_robots=num_working-data_length\n",
    "            countfailed_robots_failedexp[\"_\".join((k1,k2))]=failed_robots\n",
    "        else:\n",
    "            print(\"ERR\")\n",
    "successful_seeds=np.array(successful_seeds)\n",
    "failed_seeds=np.array(failed_seeds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# swarm_step_data[i]=(timestep,picked_pattern,picked_pattern_prob,\n",
    "#                                 correct_pattern_prob,total_received_messages,\n",
    "#                                 total_pruned_messages,total_lying_messages,\n",
    "#                                 total_lying_messages_believed,current_threshold)\n",
    "\n",
    "# Timestep vs. Working Robot Ratio\n",
    "# Timestep vs. Density\n",
    "\n",
    "Density vs. Working robot ratio\n",
    "Noise vs working robot ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**---**\n",
    "\n",
    "# Converged Experiments with 0% sensor noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Creation for successful seeds with 0 % sensor noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the needed dictionary\n",
    "converged_00=Customdictionary()\n",
    "\n",
    "for ind in range(len(successful_seeds)):\n",
    "    temp=successful_seeds[ind].split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    key_0=\"nrobots{}_nliars{}_noise{}_density{}\".format(num_robots,num_liars,noise,density)\n",
    "    key_1=\"seed{}\".format(seed)\n",
    "    \n",
    "    if (noise==0.0):\n",
    "        converged_00[successful_seeds[ind]]=pickle_dictionary[key_0][key_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries for timestep and density ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_converged_00=collections.defaultdict(dict)\n",
    "density_converged_00=collections.defaultdict(dict)\n",
    "\n",
    "for k,v in converged_00.items():\n",
    "    k_id=k.split(\"_\")\n",
    "    num_robots=int(remove_chars(k_id[0]))\n",
    "    num_liars=int(remove_chars(k_id[1]))\n",
    "    num_working=num_robots-num_liars\n",
    "    noise=float(remove_chars(k_id[2]))\n",
    "    density=int(remove_chars(k_id[3]))\n",
    "    seed=int(remove_chars(k_id[4]))\n",
    "    \n",
    "    key=\"nrobots{}_nliars{}_noise{}_density{}\".format(num_robots,num_liars,noise,density)\n",
    "    key2=\"_\".join((key,\"seed{}\".format(seed)))\n",
    "    raw_data=np.array(v).reshape((num_working,9))\n",
    "        \n",
    "    timestep=raw_data[0,0]\n",
    "    correct_pattern_prob=raw_data[:,2]\n",
    "    total_received_messages=raw_data[:,4]\n",
    "    total_pruned_messages=raw_data[:,5]\n",
    "    total_lying_messages=raw_data[:,6]\n",
    "    total_lying_messages_believed=raw_data[:,7]\n",
    "    current_threshold=raw_data[:,8] \n",
    "\n",
    "    average_pattern_prob=np.mean(correct_pattern_prob)\n",
    "    average_sum_received=np.mean(total_received_messages)\n",
    "    average_sum_pruned=np.mean(total_pruned_messages)\n",
    "    average_sum_lying=np.mean(total_lying_messages)\n",
    "    average_sum_lying_believed=np.mean(total_lying_messages_believed)\n",
    "    average_threshold=np.mean(current_threshold)\n",
    "    \n",
    "    \n",
    "    x_val=round(float(num_working/num_robots),2) # Working robots\n",
    "    y_val=timestep\n",
    "    #1\n",
    "    if not keys_exists(time_converged_00,x_val,key):\n",
    "        data=np.array(y_val)\n",
    "        time_converged_00[x_val][key]=data\n",
    "    else:\n",
    "        data=time_converged_00[x_val][key]\n",
    "        data=np.hstack((data,y_val))\n",
    "        time_converged_00[x_val][key]=data\n",
    "    #2\n",
    "    if not keys_exists(density_converged_00,density,key):\n",
    "        data=np.array(y_val)\n",
    "        density_converged_00[density][key]=data\n",
    "    else:\n",
    "        data=density_converged_00[density][key]\n",
    "        data=np.hstack((data,y_val))\n",
    "        density_converged_00[density][key]=data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Boxplot Time to converge vs. Working robot ratio \n",
    "Converged Experiments (0% sensor noise)\n",
    "Color: Density or Number of Robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes=[]\n",
    "keys=[]\n",
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.xlim(0.4,1)\n",
    "\n",
    "color_count=0\n",
    "color_map=cm.Set1(np.linspace(0,1,31))\n",
    "\n",
    "for key,value in time_converged_00.items():\n",
    "    counter=0\n",
    "    for k2,v2 in value.items():\n",
    "        identifier=k2.split(\"_\")\n",
    "        num_robots=int(remove_chars(identifier[0]))\n",
    "        num_liars=int(remove_chars(identifier[1]))\n",
    "        noise=float(remove_chars(identifier[2]))\n",
    "        density=int(remove_chars(identifier[3]))\n",
    "        \n",
    "        ###\n",
    "        #Colormap according to either TOTAL ROBOTS or DENSITY\n",
    "        keys.append('{} total robots'.format(num_robots))\n",
    "#         keys.append('Density of {}'.format(density))\n",
    "        boxplot_x=key+(0.01*counter)-0.015\n",
    "        counter+=1\n",
    "        boxplot_y=np.array(v2).reshape((v2.size,1))\n",
    "        color=color_map[num_robots]\n",
    "#         color=color_map[density]\n",
    "        ###\n",
    "        \n",
    "        box=plt.boxplot(boxplot_y,patch_artist=True,positions=[boxplot_x],labels=[str(k2)],widths=0.005)\n",
    "        boxes+=[box['boxes'][0]]\n",
    "        for patch in (box['boxes']):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "ticks=[0.2,0.25,0.4,0.5,0.6,0.7,0.75,0.8,0.85,0.88,0.9,0.95,1.0]\n",
    "plt.xticks(ticks,ticks)        \n",
    "plt.grid(True)\n",
    "plt.xlabel('Working Robot Ratio')\n",
    "plt.ylabel('Timestep')\n",
    "plt.legend(boxes,keys,loc='upper center',bbox_to_anchor=(0.5,-0.05),ncol=4)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Boxplot Time to converge vs. Density\n",
    "Converged Experiments (0% sensor noise)\n",
    "Color: Number of Robots or Number of liars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes=[]\n",
    "keys=[]\n",
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.xlim(1,10)\n",
    "\n",
    "color_count=0\n",
    "color_map=cm.Set1(np.linspace(0,1,31))\n",
    "\n",
    "for key,value in density_converged_00.items():\n",
    "    counter=0\n",
    "    for k2,v2 in value.items():\n",
    "        identifier=k2.split(\"_\")\n",
    "        num_robots=int(remove_chars(identifier[0]))\n",
    "        num_liars=int(remove_chars(identifier[1]))\n",
    "        noise=float(remove_chars(identifier[2]))\n",
    "        density=int(remove_chars(identifier[3]))\n",
    "        \n",
    "        ###\n",
    "        #Colormap according to either TOTAL ROBOTS or DENSITY\n",
    "        keys.append('{} total robots'.format(num_robots))\n",
    "#         keys.append('{} liars'.format(num_liars))\n",
    "        boxplot_x=key+(0.5*counter)-0.5\n",
    "        counter+=1\n",
    "        boxplot_y=np.array(v2).reshape((v2.size,1))\n",
    "        color=color_map[num_robots]\n",
    "#         color=color_map[num_liars]\n",
    "        ###\n",
    "        \n",
    "        box=plt.boxplot(boxplot_y,patch_artist=True,positions=[boxplot_x],labels=[str(k2)],widths=0.5)\n",
    "        boxes+=[box['boxes'][0]]\n",
    "        for patch in (box['boxes']):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "ticks=[1.0,2.0,5.0,10.0]\n",
    "plt.xticks(ticks,ticks)        \n",
    "plt.grid(True)\n",
    "plt.xlabel('Density')\n",
    "plt.ylabel('Timestep')\n",
    "plt.legend(boxes,keys,loc='upper center',bbox_to_anchor=(0.5,-0.05),ncol=4)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**---**\n",
    "\n",
    "# Converged Experiments with 10% sensor noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Creation for successful seeds with 10 % sensor noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the needed dictionary\n",
    "converged_10=Customdictionary()\n",
    "\n",
    "for ind in range(len(successful_seeds)):\n",
    "    temp=successful_seeds[ind].split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    key_0=\"nrobots{}_nliars{}_noise{}_density{}\".format(num_robots,num_liars,noise,density)\n",
    "    key_1=\"seed{}\".format(seed)\n",
    "    \n",
    "    if (noise==0.10):\n",
    "        converged_10[successful_seeds[ind]]=pickle_dictionary[key_0][key_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries for timestep and density ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_converged_10=collections.defaultdict(dict)\n",
    "density_converged_10=collections.defaultdict(dict)\n",
    "\n",
    "for k,v in converged_10.items():\n",
    "    k_id=k.split(\"_\")\n",
    "    num_robots=int(remove_chars(k_id[0]))\n",
    "    num_liars=int(remove_chars(k_id[1]))\n",
    "    num_working=num_robots-num_liars\n",
    "    noise=float(remove_chars(k_id[2]))\n",
    "    density=int(remove_chars(k_id[3]))\n",
    "    seed=int(remove_chars(k_id[4]))\n",
    "    \n",
    "    key=\"nrobots{}_nliars{}_noise{}_density{}\".format(num_robots,num_liars,noise,density)\n",
    "    key2=\"_\".join((key,\"seed{}\".format(seed)))\n",
    "    raw_data=np.array(v).reshape((num_working,9))\n",
    "        \n",
    "    timestep=raw_data[0,0]\n",
    "    correct_pattern_prob=raw_data[:,2]\n",
    "    total_received_messages=raw_data[:,4]\n",
    "    total_pruned_messages=raw_data[:,5]\n",
    "    total_lying_messages=raw_data[:,6]\n",
    "    total_lying_messages_believed=raw_data[:,7]\n",
    "    current_threshold=raw_data[:,8] \n",
    "\n",
    "    average_pattern_prob=np.mean(correct_pattern_prob)\n",
    "    average_sum_received=np.mean(total_received_messages)\n",
    "    average_sum_pruned=np.mean(total_pruned_messages)\n",
    "    average_sum_lying=np.mean(total_lying_messages)\n",
    "    average_sum_lying_believed=np.mean(total_lying_messages_believed)\n",
    "    average_threshold=np.mean(current_threshold)\n",
    "    \n",
    "    \n",
    "    x_val=round(float(num_working/num_robots),2) # Working robots\n",
    "    y_val=timestep\n",
    "    #1\n",
    "    if not keys_exists(time_converged_10,x_val,key):\n",
    "        data=np.array(y_val)\n",
    "        time_converged_10[x_val][key]=data\n",
    "    else:\n",
    "        data=time_converged_10[x_val][key]\n",
    "        data=np.hstack((data,y_val))\n",
    "        time_converged_10[x_val][key]=data\n",
    "    #2\n",
    "    if not keys_exists(density_converged_10,density,key):\n",
    "        data=np.array(y_val)\n",
    "        density_converged_10[density][key]=data\n",
    "    else:\n",
    "        data=density_converged_10[density][key]\n",
    "        data=np.hstack((data,y_val))\n",
    "        density_converged_10[density][key]=data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Boxplot Time to converge vs. Working robot ratio \n",
    "Converged Experiments (10% sensor noise)\n",
    "Color: Density or Number of Robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes=[]\n",
    "keys=[]\n",
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.xlim(0.4,1)\n",
    "\n",
    "color_count=0\n",
    "color_map=cm.Set1(np.linspace(0,1,31))\n",
    "\n",
    "for key,value in time_converged_10.items():\n",
    "    counter=0\n",
    "    for k2,v2 in value.items():\n",
    "        identifier=k2.split(\"_\")\n",
    "        num_robots=int(remove_chars(identifier[0]))\n",
    "        num_liars=int(remove_chars(identifier[1]))\n",
    "        noise=float(remove_chars(identifier[2]))\n",
    "        density=int(remove_chars(identifier[3]))\n",
    "        \n",
    "        ###\n",
    "        #Colormap according to either TOTAL ROBOTS or DENSITY\n",
    "        keys.append('{} total robots'.format(num_robots))\n",
    "#         keys.append('Density of {}'.format(density))\n",
    "        boxplot_x=key+(0.01*counter)-0.015\n",
    "        counter+=1\n",
    "        boxplot_y=np.array(v2).reshape((v2.size,1))\n",
    "        color=color_map[num_robots]\n",
    "#         color=color_map[density]\n",
    "        ###\n",
    "        \n",
    "        box=plt.boxplot(boxplot_y,patch_artist=True,positions=[boxplot_x],labels=[str(k2)],widths=0.005)\n",
    "        boxes+=[box['boxes'][0]]\n",
    "        for patch in (box['boxes']):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "ticks=[0.2,0.25,0.4,0.5,0.6,0.7,0.75,0.8,0.85,0.88,0.9,0.95,1.0]\n",
    "plt.xticks(ticks,ticks)        \n",
    "plt.grid(True)\n",
    "plt.xlabel('Working Robot Ratio')\n",
    "plt.ylabel('Timestep')\n",
    "plt.legend(boxes,keys,loc='upper center',bbox_to_anchor=(0.5,-0.05),ncol=4)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Boxplot Time to converge vs. Density\n",
    "Converged Experiments (10% sensor noise)\n",
    "Color: Number of Robots or Number of liars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes=[]\n",
    "keys=[]\n",
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.xlim(1,10)\n",
    "\n",
    "color_count=0\n",
    "color_map=cm.Set1(np.linspace(0,1,31))\n",
    "\n",
    "for key,value in density_converged_10.items():\n",
    "    counter=0\n",
    "    for k2,v2 in value.items():\n",
    "        identifier=k2.split(\"_\")\n",
    "        num_robots=int(remove_chars(identifier[0]))\n",
    "        num_liars=int(remove_chars(identifier[1]))\n",
    "        noise=float(remove_chars(identifier[2]))\n",
    "        density=int(remove_chars(identifier[3]))\n",
    "        \n",
    "        ###\n",
    "        #Colormap according to either TOTAL ROBOTS or DENSITY\n",
    "        keys.append('{} total robots'.format(num_robots))\n",
    "#         keys.append('{} liars'.format(num_liars))\n",
    "        boxplot_x=key+(0.5*counter)-0.5\n",
    "        counter+=1\n",
    "        boxplot_y=np.array(v2).reshape((v2.size,1))\n",
    "        color=color_map[num_robots]\n",
    "#         color=color_map[num_liars]\n",
    "        ###\n",
    "        \n",
    "        box=plt.boxplot(boxplot_y,patch_artist=True,positions=[boxplot_x],labels=[str(k2)],widths=0.5)\n",
    "        boxes+=[box['boxes'][0]]\n",
    "        for patch in (box['boxes']):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "ticks=[1.0,2.0,5.0,10.0]\n",
    "plt.xticks(ticks,ticks)        \n",
    "plt.grid(True)\n",
    "plt.xlabel('Density')\n",
    "plt.ylabel('Timestep')\n",
    "plt.legend(boxes,keys,loc='upper center',bbox_to_anchor=(0.5,-0.05),ncol=4)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**---**\n",
    "\n",
    "# Converged Experiments with 20% sensor noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Creation for successful seeds with 20 % sensor noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the needed dictionary\n",
    "converged_20=Customdictionary()\n",
    "\n",
    "for ind in range(len(successful_seeds)):\n",
    "    temp=successful_seeds[ind].split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    key_0=\"nrobots{}_nliars{}_noise{}_density{}\".format(num_robots,num_liars,noise,density)\n",
    "    key_1=\"seed{}\".format(seed)\n",
    "    \n",
    "    if (noise==0.20):\n",
    "        converged_20[successful_seeds[ind]]=pickle_dictionary[key_0][key_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries for timestep and density ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_converged_20=collections.defaultdict(dict)\n",
    "density_converged_20=collections.defaultdict(dict)\n",
    "\n",
    "for k,v in converged_20.items():\n",
    "    k_id=k.split(\"_\")\n",
    "    num_robots=int(remove_chars(k_id[0]))\n",
    "    num_liars=int(remove_chars(k_id[1]))\n",
    "    num_working=num_robots-num_liars\n",
    "    noise=float(remove_chars(k_id[2]))\n",
    "    density=int(remove_chars(k_id[3]))\n",
    "    seed=int(remove_chars(k_id[4]))\n",
    "    \n",
    "    key=\"nrobots{}_nliars{}_noise{}_density{}\".format(num_robots,num_liars,noise,density)\n",
    "    key2=\"_\".join((key,\"seed{}\".format(seed)))\n",
    "    raw_data=np.array(v).reshape((num_working,9))\n",
    "        \n",
    "    timestep=raw_data[0,0]\n",
    "    correct_pattern_prob=raw_data[:,2]\n",
    "    total_received_messages=raw_data[:,4]\n",
    "    total_pruned_messages=raw_data[:,5]\n",
    "    total_lying_messages=raw_data[:,6]\n",
    "    total_lying_messages_believed=raw_data[:,7]\n",
    "    current_threshold=raw_data[:,8] \n",
    "\n",
    "    average_pattern_prob=np.mean(correct_pattern_prob)\n",
    "    average_sum_received=np.mean(total_received_messages)\n",
    "    average_sum_pruned=np.mean(total_pruned_messages)\n",
    "    average_sum_lying=np.mean(total_lying_messages)\n",
    "    average_sum_lying_believed=np.mean(total_lying_messages_believed)\n",
    "    average_threshold=np.mean(current_threshold)\n",
    "    \n",
    "    \n",
    "    x_val=round(float(num_working/num_robots),2) # Working robots\n",
    "    y_val=timestep\n",
    "    #1\n",
    "    if not keys_exists(time_converged_20,x_val,key):\n",
    "        data=np.array(y_val)\n",
    "        time_converged_20[x_val][key]=data\n",
    "    else:\n",
    "        data=time_converged_20[x_val][key]\n",
    "        data=np.hstack((data,y_val))\n",
    "        time_converged_20[x_val][key]=data\n",
    "    #2\n",
    "    if not keys_exists(density_converged_20,density,key):\n",
    "        data=np.array(y_val)\n",
    "        density_converged_20[density][key]=data\n",
    "    else:\n",
    "        data=density_converged_20[density][key]\n",
    "        data=np.hstack((data,y_val))\n",
    "        density_converged_20[density][key]=data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Boxplot Time to converge vs. Working robot ratio \n",
    "Converged Experiments (20% sensor noise)\n",
    "Color: Density or Number of Robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes=[]\n",
    "keys=[]\n",
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.xlim(0.4,1)\n",
    "\n",
    "color_count=0\n",
    "color_map=cm.Set1(np.linspace(0,1,51))\n",
    "\n",
    "for key,value in time_converged_20.items():\n",
    "    counter=0\n",
    "    for k2,v2 in value.items():\n",
    "        identifier=k2.split(\"_\")\n",
    "        num_robots=int(remove_chars(identifier[0]))\n",
    "        num_liars=int(remove_chars(identifier[1]))\n",
    "        noise=float(remove_chars(identifier[2]))\n",
    "        density=int(remove_chars(identifier[3]))\n",
    "        \n",
    "        ###\n",
    "        #Colormap according to either TOTAL ROBOTS or DENSITY\n",
    "        keys.append('{} total robots'.format(num_robots))\n",
    "#         keys.append('Density of {}'.format(density))\n",
    "        boxplot_x=key+(0.01*counter)-0.015\n",
    "        counter+=1\n",
    "        boxplot_y=np.array(v2).reshape((v2.size,1))\n",
    "        color=color_map[num_robots]\n",
    "#         color=color_map[density]\n",
    "        ###\n",
    "        \n",
    "        box=plt.boxplot(boxplot_y,patch_artist=True,positions=[boxplot_x],labels=[str(k2)],widths=0.005)\n",
    "        boxes+=[box['boxes'][0]]\n",
    "        for patch in (box['boxes']):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "ticks=[0.2,0.25,0.4,0.5,0.6,0.7,0.75,0.8,0.85,0.88,0.9,0.95,1.0]\n",
    "plt.xticks(ticks,ticks)        \n",
    "plt.grid(True)\n",
    "plt.xlabel('Working Robot Ratio')\n",
    "plt.ylabel('Timestep')\n",
    "plt.legend(boxes,keys,loc='upper center',bbox_to_anchor=(0.5,-0.05),ncol=4)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Boxplot Time to converge vs. Density\n",
    "Converged Experiments (20% sensor noise)\n",
    "Color: Number of Robots or Number of liars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes=[]\n",
    "keys=[]\n",
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.xlim(1,10)\n",
    "\n",
    "color_count=0\n",
    "color_map=cm.Set1(np.linspace(0,1,51))\n",
    "\n",
    "for key,value in density_converged_20.items():\n",
    "    counter=0\n",
    "    for k2,v2 in value.items():\n",
    "        identifier=k2.split(\"_\")\n",
    "        num_robots=int(remove_chars(identifier[0]))\n",
    "        num_liars=int(remove_chars(identifier[1]))\n",
    "        noise=float(remove_chars(identifier[2]))\n",
    "        density=int(remove_chars(identifier[3]))\n",
    "        \n",
    "        ###\n",
    "        #Colormap according to either TOTAL ROBOTS or DENSITY\n",
    "        keys.append('{} total robots'.format(num_robots))\n",
    "#         keys.append('{} liars'.format(num_liars))\n",
    "        boxplot_x=key+(0.5*counter)-0.5\n",
    "        counter+=1\n",
    "        boxplot_y=np.array(v2).reshape((v2.size,1))\n",
    "        color=color_map[num_robots]\n",
    "#         color=color_map[num_liars]\n",
    "        ###\n",
    "        \n",
    "        box=plt.boxplot(boxplot_y,patch_artist=True,positions=[boxplot_x],labels=[str(k2)],widths=0.5)\n",
    "        boxes+=[box['boxes'][0]]\n",
    "        for patch in (box['boxes']):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "ticks=[1.0,2.0,5.0,10.0]\n",
    "plt.xticks(ticks,ticks)        \n",
    "plt.grid(True)\n",
    "plt.xlabel('Density')\n",
    "plt.ylabel('Timestep')\n",
    "plt.legend(boxes,keys,loc='upper center',bbox_to_anchor=(0.5,-0.05),ncol=4)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**---**\n",
    "\n",
    "# Converged Experiments with 40% sensor noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Creation for successful seeds with 40 % sensor noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the needed dictionary\n",
    "converged_40=Customdictionary()\n",
    "\n",
    "for ind in range(len(successful_seeds)):\n",
    "    temp=successful_seeds[ind].split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    key_0=\"nrobots{}_nliars{}_noise{}_density{}\".format(num_robots,num_liars,noise,density)\n",
    "    key_1=\"seed{}\".format(seed)\n",
    "    \n",
    "    if (noise==0.0):\n",
    "        converged_40[successful_seeds[ind]]=pickle_dictionary[key_0][key_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries for timestep and density ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_converged_40=collections.defaultdict(dict)\n",
    "density_converged_40=collections.defaultdict(dict)\n",
    "\n",
    "for k,v in converged_40.items():\n",
    "    k_id=k.split(\"_\")\n",
    "    num_robots=int(remove_chars(k_id[0]))\n",
    "    num_liars=int(remove_chars(k_id[1]))\n",
    "    num_working=num_robots-num_liars\n",
    "    noise=float(remove_chars(k_id[2]))\n",
    "    density=int(remove_chars(k_id[3]))\n",
    "    seed=int(remove_chars(k_id[4]))\n",
    "    \n",
    "    key=\"nrobots{}_nliars{}_noise{}_density{}\".format(num_robots,num_liars,noise,density)\n",
    "    key2=\"_\".join((key,\"seed{}\".format(seed)))\n",
    "    raw_data=np.array(v).reshape((num_working,9))\n",
    "        \n",
    "    timestep=raw_data[0,0]\n",
    "    correct_pattern_prob=raw_data[:,2]\n",
    "    total_received_messages=raw_data[:,4]\n",
    "    total_pruned_messages=raw_data[:,5]\n",
    "    total_lying_messages=raw_data[:,6]\n",
    "    total_lying_messages_believed=raw_data[:,7]\n",
    "    current_threshold=raw_data[:,8] \n",
    "\n",
    "    average_pattern_prob=np.mean(correct_pattern_prob)\n",
    "    average_sum_received=np.mean(total_received_messages)\n",
    "    average_sum_pruned=np.mean(total_pruned_messages)\n",
    "    average_sum_lying=np.mean(total_lying_messages)\n",
    "    average_sum_lying_believed=np.mean(total_lying_messages_believed)\n",
    "    average_threshold=np.mean(current_threshold)\n",
    "    \n",
    "    \n",
    "    x_val=round(float(num_working/num_robots),2) # Working robots\n",
    "    y_val=timestep\n",
    "    #1\n",
    "    if not keys_exists(time_converged_40,x_val,key):\n",
    "        data=np.array(y_val)\n",
    "        time_converged_40[x_val][key]=data\n",
    "    else:\n",
    "        data=time_converged_40[x_val][key]\n",
    "        data=np.hstack((data,y_val))\n",
    "        time_converged_40[x_val][key]=data\n",
    "    #2\n",
    "    if not keys_exists(density_converged_40,density,key):\n",
    "        data=np.array(y_val)\n",
    "        density_converged_40[density][key]=data\n",
    "    else:\n",
    "        data=density_converged_40[density][key]\n",
    "        data=np.hstack((data,y_val))\n",
    "        density_converged_40[density][key]=data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Boxplot Time to converge vs. Working robot ratio \n",
    "Converged Experiments (40% sensor noise)\n",
    "Color: Density or Number of Robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes=[]\n",
    "keys=[]\n",
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.xlim(0.4,1)\n",
    "\n",
    "color_count=0\n",
    "color_map=cm.Set1(np.linspace(0,1,31))\n",
    "\n",
    "for key,value in time_converged_40.items():\n",
    "    counter=0\n",
    "    for k2,v2 in value.items():\n",
    "        identifier=k2.split(\"_\")\n",
    "        num_robots=int(remove_chars(identifier[0]))\n",
    "        num_liars=int(remove_chars(identifier[1]))\n",
    "        noise=float(remove_chars(identifier[2]))\n",
    "        density=int(remove_chars(identifier[3]))\n",
    "        \n",
    "        ###\n",
    "        #Colormap according to either TOTAL ROBOTS or DENSITY\n",
    "        keys.append('{} total robots'.format(num_robots))\n",
    "#         keys.append('Density of {}'.format(density))\n",
    "        boxplot_x=key+(0.01*counter)-0.015\n",
    "        counter+=1\n",
    "        boxplot_y=np.array(v2).reshape((v2.size,1))\n",
    "        color=color_map[num_robots]\n",
    "#         color=color_map[density]\n",
    "        ###\n",
    "        \n",
    "        box=plt.boxplot(boxplot_y,patch_artist=True,positions=[boxplot_x],labels=[str(k2)],widths=0.005)\n",
    "        boxes+=[box['boxes'][0]]\n",
    "        for patch in (box['boxes']):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "ticks=[0.2,0.25,0.4,0.5,0.6,0.7,0.75,0.8,0.85,0.88,0.9,0.95,1.0]\n",
    "plt.xticks(ticks,ticks)        \n",
    "plt.grid(True)\n",
    "plt.xlabel('Working Robot Ratio')\n",
    "plt.ylabel('Timestep')\n",
    "plt.legend(boxes,keys,loc='upper center',bbox_to_anchor=(0.5,-0.05),ncol=4)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Boxplot Time to converge vs. Density\n",
    "Converged Experiments (40% sensor noise)\n",
    "Color: Number of Robots or Number of liars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes=[]\n",
    "keys=[]\n",
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.xlim(1,10)\n",
    "\n",
    "color_count=0\n",
    "color_map=cm.Set1(np.linspace(0,1,31))\n",
    "\n",
    "for key,value in density_converged_40.items():\n",
    "    counter=0\n",
    "    for k2,v2 in value.items():\n",
    "        identifier=k2.split(\"_\")\n",
    "        num_robots=int(remove_chars(identifier[0]))\n",
    "        num_liars=int(remove_chars(identifier[1]))\n",
    "        noise=float(remove_chars(identifier[2]))\n",
    "        density=int(remove_chars(identifier[3]))\n",
    "        \n",
    "        ###\n",
    "        #Colormap according to either TOTAL ROBOTS or DENSITY\n",
    "        keys.append('{} total robots'.format(num_robots))\n",
    "#         keys.append('{} liars'.format(num_liars))\n",
    "        boxplot_x=key+(0.5*counter)-0.5\n",
    "        counter+=1\n",
    "        boxplot_y=np.array(v2).reshape((v2.size,1))\n",
    "        color=color_map[num_robots]\n",
    "#         color=color_map[num_liars]\n",
    "        ###\n",
    "        \n",
    "        box=plt.boxplot(boxplot_y,patch_artist=True,positions=[boxplot_x],labels=[str(k2)],widths=0.5)\n",
    "        boxes+=[box['boxes'][0]]\n",
    "        for patch in (box['boxes']):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "ticks=[1.0,2.0,5.0,10.0]\n",
    "plt.xticks(ticks,ticks)        \n",
    "plt.grid(True)\n",
    "plt.xlabel('Density')\n",
    "plt.ylabel('Timestep')\n",
    "plt.legend(boxes,keys,loc='upper center',bbox_to_anchor=(0.5,-0.05),ncol=4)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Heatmap Successful Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Creation for all successful seeds separated by sensor noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separating data based on sensor noise\n",
    "heatmap_converged_dict_00=Customdictionary()\n",
    "heatmap_converged_dict_05=Customdictionary()\n",
    "heatmap_converged_dict_10=Customdictionary()\n",
    "heatmap_converged_dict_20=Customdictionary()\n",
    "heatmap_converged_dict_25=Customdictionary()\n",
    "heatmap_converged_dict_30=Customdictionary()\n",
    "heatmap_converged_dict_40=Customdictionary()\n",
    "\n",
    "for ind in range(len(successful_seeds)):\n",
    "    temp=successful_seeds[ind].split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    key_0=\"nrobots{}_nliars{}_noise{}_density{}\".format(num_robots,num_liars,noise,density)\n",
    "    key_1=\"seed{}\".format(seed)\n",
    "\n",
    "    \n",
    "    raw_data=pickle_dictionary[key_0][key_1]\n",
    "    raw_data=np.array(raw_data).reshape((num_working,9)) #From pickle dictionary\n",
    "        \n",
    "    timestep=raw_data[0,0]\n",
    "    correct_pattern_prob=raw_data[:,2]\n",
    "    total_received_messages=raw_data[:,4]\n",
    "    total_pruned_messages=raw_data[:,5]\n",
    "    total_lying_messages=raw_data[:,6]\n",
    "    total_lying_messages_believed=raw_data[:,7]\n",
    "    current_threshold=raw_data[:,8] \n",
    "\n",
    "    average_pattern_prob=np.mean(correct_pattern_prob)\n",
    "    average_sum_received=np.mean(total_received_messages)\n",
    "    average_sum_pruned=np.mean(total_pruned_messages)\n",
    "    average_sum_lying=np.mean(total_lying_messages)\n",
    "    average_sum_lying_believed=np.mean(total_lying_messages_believed)\n",
    "    average_threshold=np.mean(current_threshold)\n",
    "  \n",
    "    if (noise==0.0):\n",
    "        str_noise=str(noise)\n",
    "        str_defecting_robotratio=str(float(num_liars/num_robots))\n",
    "        key=\"_\".join((str_noise,str_defecting_robotratio))\n",
    "        value=int(timestep)\n",
    "        heatmap_converged_dict_00[key]=value\n",
    "    elif (noise==0.05):\n",
    "        str_noise=str(noise)\n",
    "        str_defecting_robotratio=str(float(num_liars/num_robots))\n",
    "        key=\"_\".join((str_noise,str_defecting_robotratio))\n",
    "        value=int(timestep)\n",
    "        heatmap_converged_dict_05[key]=value\n",
    "    elif (noise==0.10):\n",
    "        str_noise=str(noise)\n",
    "        str_defecting_robotratio=str(float(num_liars/num_robots))\n",
    "        key=\"_\".join((str_noise,str_defecting_robotratio))\n",
    "        value=int(timestep)\n",
    "        heatmap_converged_dict_10[key]=value\n",
    "    elif (noise==0.20):\n",
    "        str_noise=str(noise)\n",
    "        str_defecting_robotratio=str(float(num_liars/num_robots))\n",
    "        key=\"_\".join((str_noise,str_defecting_robotratio))\n",
    "        value=int(timestep)\n",
    "        heatmap_converged_dict_20[key]=value\n",
    "    elif (noise==0.25):\n",
    "        str_noise=str(noise)\n",
    "        str_defecting_robotratio=str(float(num_liars/num_robots))\n",
    "        key=\"_\".join((str_noise,str_defecting_robotratio))\n",
    "        value=int(timestep)\n",
    "        heatmap_converged_dict_25[key]=value\n",
    "    elif (noise==0.30):\n",
    "        str_noise=str(noise)\n",
    "        str_defecting_robotratio=str(float(num_liars/num_robots))\n",
    "        key=\"_\".join((str_noise,str_defecting_robotratio))\n",
    "        value=int(timestep)\n",
    "        heatmap_converged_dict_30[key]=value\n",
    "    elif (noise==0.40):\n",
    "        str_noise=str(noise)\n",
    "        str_defecting_robotratio=str(float(num_liars/num_robots))\n",
    "        key=\"_\".join((str_noise,str_defecting_robotratio))\n",
    "        value=int(timestep)\n",
    "        heatmap_converged_dict_40[key]=value\n",
    "    else:\n",
    "        print(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summaries\n",
    "count_tstep_summary_dict_00=Customdictionary()\n",
    "count_tstep_summary_dict_05=Customdictionary()\n",
    "count_tstep_summary_dict_10=Customdictionary()\n",
    "count_tstep_summary_dict_20=Customdictionary()\n",
    "count_tstep_summary_dict_25=Customdictionary()\n",
    "count_tstep_summary_dict_30=Customdictionary()\n",
    "count_tstep_summary_dict_40=Customdictionary()\n",
    "\n",
    "mean_tstep_summary_dict_00=Customdictionary()\n",
    "mean_tstep_summary_dict_05=Customdictionary()\n",
    "mean_tstep_summary_dict_10=Customdictionary()\n",
    "mean_tstep_summary_dict_20=Customdictionary()\n",
    "mean_tstep_summary_dict_25=Customdictionary()\n",
    "mean_tstep_summary_dict_30=Customdictionary()\n",
    "mean_tstep_summary_dict_40=Customdictionary()\n",
    "\n",
    "for key, value in heatmap_converged_dict_00.items():\n",
    "    key=key.split(\"_\")[1]\n",
    "    successful_experiments=len(value)\n",
    "    mean_tstep=np.mean(value)\n",
    "#     summary_dict_00[key]=successful_experiments,round(mean_tstep)\n",
    "    count_tstep_summary_dict_00[key]=successful_experiments\n",
    "    mean_tstep_summary_dict_00[key]=round(mean_tstep)\n",
    "    \n",
    "for key, value in heatmap_converged_dict_05.items():\n",
    "    key=key.split(\"_\")[1]\n",
    "    successful_experiments=len(value)\n",
    "    mean_tstep=np.mean(value)\n",
    "#     summary_dict_05[key]=successful_experiments,round(mean_tstep)\n",
    "    count_tstep_summary_dict_05[key]=successful_experiments\n",
    "    mean_tstep_summary_dict_05[key]=round(mean_tstep)\n",
    "\n",
    "for key, value in heatmap_converged_dict_10.items():\n",
    "    key=key.split(\"_\")[1]\n",
    "    successful_experiments=len(value)\n",
    "    mean_tstep=np.mean(value)\n",
    "#     summary_dict_10[key]=successful_experiments,round(mean_tstep)\n",
    "    count_tstep_summary_dict_10[key]=successful_experiments\n",
    "    mean_tstep_summary_dict_10[key]=round(mean_tstep)\n",
    "\n",
    "for key, value in heatmap_converged_dict_20.items():\n",
    "    key=key.split(\"_\")[1]\n",
    "    successful_experiments=len(value)\n",
    "    mean_tstep=np.mean(value)\n",
    "#     summary_dict_20[key]=successful_experiments,round(mean_tstep)\n",
    "    count_tstep_summary_dict_20[key]=successful_experiments\n",
    "    mean_tstep_summary_dict_20[key]=round(mean_tstep)\n",
    "\n",
    "for key, value in heatmap_converged_dict_25.items():\n",
    "    key=key.split(\"_\")[1]\n",
    "    successful_experiments=len(value)\n",
    "    mean_tstep=np.mean(value)\n",
    "#     summary_dict_25[key]=successful_experiments,round(mean_tstep)\n",
    "    count_tstep_summary_dict_25[key]=successful_experiments\n",
    "    mean_tstep_summary_dict_25[key]=round(mean_tstep)\n",
    "\n",
    "for key, value in heatmap_converged_dict_30.items():\n",
    "    key=key.split(\"_\")[1]\n",
    "    successful_experiments=len(value)\n",
    "    mean_tstep=np.mean(value)\n",
    "#     summary_dict_30[key]=successful_experiments,round(mean_tstep)\n",
    "    count_tstep_summary_dict_30[key]=successful_experiments\n",
    "    mean_tstep_summary_dict_30[key]=round(mean_tstep)\n",
    "\n",
    "for key, value in heatmap_converged_dict_40.items():\n",
    "    key=key.split(\"_\")[1]\n",
    "    successful_experiments=len(value)\n",
    "    mean_tstep=np.mean(value)\n",
    "#     summary_dict_40[key]=successful_experiments,round(mean_tstep)\n",
    "    count_tstep_summary_dict_40[key]=successful_experiments\n",
    "    mean_tstep_summary_dict_40[key]=round(mean_tstep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Count of successful experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to create an array from the summary dictionaries.\n",
    "index=['0.00']\n",
    "ct_df1=pd.DataFrame(data=count_tstep_summary_dict_00,index=index)\n",
    "index=['0.05']\n",
    "ct_df2=pd.DataFrame(data=count_tstep_summary_dict_05,index=index)\n",
    "index=['0.10']\n",
    "ct_df3=pd.DataFrame(data=count_tstep_summary_dict_10,index=index)\n",
    "index=['0.20']\n",
    "ct_df4=pd.DataFrame(data=count_tstep_summary_dict_20,index=index)\n",
    "index=['0.25']\n",
    "ct_df5=pd.DataFrame(data=count_tstep_summary_dict_25,index=index)\n",
    "index=['0.30']\n",
    "ct_df6=pd.DataFrame(data=count_tstep_summary_dict_30,index=index)\n",
    "index=['0.40']\n",
    "ct_df7=pd.DataFrame(data=count_tstep_summary_dict_40,index=index)\n",
    "\n",
    "ct_df_all=ct_df7.append(ct_df6).append(ct_df5).append(ct_df4).append(ct_df3).append(ct_df2).append(ct_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Mean timestep for successful experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to create an array from the summary dictionaries. Shoddy code\n",
    "index=['0.00']\n",
    "mt_df1=pd.DataFrame(data=mean_tstep_summary_dict_00,index=index)\n",
    "index=['0.05']\n",
    "mt_df2=pd.DataFrame(data=mean_tstep_summary_dict_05,index=index)\n",
    "index=['0.10']\n",
    "mt_df3=pd.DataFrame(data=mean_tstep_summary_dict_10,index=index)\n",
    "index=['0.20']\n",
    "mt_df4=pd.DataFrame(data=mean_tstep_summary_dict_20,index=index)\n",
    "index=['0.25']\n",
    "mt_df5=pd.DataFrame(data=mean_tstep_summary_dict_25,index=index)\n",
    "index=['0.30']\n",
    "mt_df6=pd.DataFrame(data=mean_tstep_summary_dict_30,index=index)\n",
    "index=['0.40']\n",
    "mt_df7=pd.DataFrame(data=mean_tstep_summary_dict_40,index=index)\n",
    "\n",
    "mt_df_all=mt_df7.append(mt_df6).append(mt_df5).append(mt_df4).append(mt_df3).append(mt_df2).append(mt_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Number of Successful Experiments [Sensor Noise vs. Defecting Ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(ct_df_all, annot=True,cmap='hot')\n",
    "plt.ylabel('Sensor Noise')\n",
    "plt.xlabel('Defecting Ratio')\n",
    "plt.title('Number of successful experiments')\n",
    "# plt.savefig(\"SuccessfulExperiments_Random\",bbox_inches='tight')\n",
    "# plt.savefig(\"SuccessfulExperiments_Defecting\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Timestep of Successful Experiments [Sensor Noise vs. Defecting Ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(mt_df_all, annot=True,cmap='summer')\n",
    "plt.ylabel('Sensor Noise')\n",
    "plt.xlabel('Defecting Ratio')\n",
    "plt.title('Mean Timestep for completion')\n",
    "# plt.savefig(\"Successful_MeanTimesteps_Random\",bbox_inches='tight')\n",
    "# plt.savefig(\"Successful_MeanTimesteps_Defecting\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Heatmap Failed Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Creation for all failed seeds separated by sensor noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separating data based on sensor noise\n",
    "heatmap_nonconverged_dict_00=Customdictionary()\n",
    "heatmap_nonconverged_dict_05=Customdictionary()\n",
    "heatmap_nonconverged_dict_10=Customdictionary()\n",
    "heatmap_nonconverged_dict_20=Customdictionary()\n",
    "heatmap_nonconverged_dict_25=Customdictionary()\n",
    "heatmap_nonconverged_dict_30=Customdictionary()\n",
    "heatmap_nonconverged_dict_40=Customdictionary()\n",
    "\n",
    "for ind in range(len(failed_seeds)):\n",
    "    temp=failed_seeds[ind].split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    key_0=\"nrobots{}_nliars{}_noise{}_density{}\".format(num_robots,num_liars,noise,density)\n",
    "    key_1=\"seed{}\".format(seed)\n",
    "\n",
    "    \n",
    "    raw_data=pickle_dictionary[key_0][key_1]\n",
    "   \n",
    "    raw_data=np.array(raw_data).reshape((len(raw_data),9)) #From pickle dictionary\n",
    "        \n",
    "    timestep=raw_data[0,0]\n",
    "    correct_pattern_prob=raw_data[:,2]\n",
    "    total_received_messages=raw_data[:,4]\n",
    "    total_pruned_messages=raw_data[:,5]\n",
    "    total_lying_messages=raw_data[:,6]\n",
    "    total_lying_messages_believed=raw_data[:,7]\n",
    "    current_threshold=raw_data[:,8] \n",
    "\n",
    "    average_pattern_prob=np.mean(correct_pattern_prob)\n",
    "    average_sum_received=np.mean(total_received_messages)\n",
    "    average_sum_pruned=np.mean(total_pruned_messages)\n",
    "    average_sum_lying=np.mean(total_lying_messages)\n",
    "    average_sum_lying_believed=np.mean(total_lying_messages_believed)\n",
    "    average_threshold=np.mean(current_threshold)\n",
    "  \n",
    "    if (noise==0.0):\n",
    "        str_noise=str(noise)\n",
    "        str_defecting_robotratio=str(float(num_liars/num_robots))\n",
    "        key=\"_\".join((str_noise,str_defecting_robotratio))\n",
    "        value=int(timestep)\n",
    "        heatmap_nonconverged_dict_00[key]=value\n",
    "    elif (noise==0.05):\n",
    "        str_noise=str(noise)\n",
    "        str_defecting_robotratio=str(float(num_liars/num_robots))\n",
    "        key=\"_\".join((str_noise,str_defecting_robotratio))\n",
    "        value=int(timestep)\n",
    "        heatmap_nonconverged_dict_05[key]=value\n",
    "    elif (noise==0.10):\n",
    "        str_noise=str(noise)\n",
    "        str_defecting_robotratio=str(float(num_liars/num_robots))\n",
    "        key=\"_\".join((str_noise,str_defecting_robotratio))\n",
    "        value=int(timestep)\n",
    "        heatmap_nonconverged_dict_10[key]=value\n",
    "    elif (noise==0.20):\n",
    "        str_noise=str(noise)\n",
    "        str_defecting_robotratio=str(float(num_liars/num_robots))\n",
    "        key=\"_\".join((str_noise,str_defecting_robotratio))\n",
    "        value=int(timestep)\n",
    "        heatmap_nonconverged_dict_20[key]=value\n",
    "    elif (noise==0.25):\n",
    "        str_noise=str(noise)\n",
    "        str_defecting_robotratio=str(float(num_liars/num_robots))\n",
    "        key=\"_\".join((str_noise,str_defecting_robotratio))\n",
    "        value=int(timestep)\n",
    "        heatmap_nonconverged_dict_25[key]=value\n",
    "    elif (noise==0.30):\n",
    "        str_noise=str(noise)\n",
    "        str_defecting_robotratio=str(float(num_liars/num_robots))\n",
    "        key=\"_\".join((str_noise,str_defecting_robotratio))\n",
    "        value=int(timestep)\n",
    "        heatmap_nonconverged_dict_30[key]=value\n",
    "    elif (noise==0.40):\n",
    "        str_noise=str(noise)\n",
    "        str_defecting_robotratio=str(float(num_liars/num_robots))\n",
    "        key=\"_\".join((str_noise,str_defecting_robotratio))\n",
    "        value=int(timestep)\n",
    "        heatmap_nonconverged_dict_40[key]=value\n",
    "    else:\n",
    "        print(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summaries\n",
    "count_tstep_summary_dict_00=Customdictionary()\n",
    "count_tstep_summary_dict_05=Customdictionary()\n",
    "count_tstep_summary_dict_10=Customdictionary()\n",
    "count_tstep_summary_dict_20=Customdictionary()\n",
    "count_tstep_summary_dict_25=Customdictionary()\n",
    "count_tstep_summary_dict_30=Customdictionary()\n",
    "count_tstep_summary_dict_40=Customdictionary()\n",
    "\n",
    "mean_tstep_summary_dict_00=Customdictionary()\n",
    "mean_tstep_summary_dict_05=Customdictionary()\n",
    "mean_tstep_summary_dict_10=Customdictionary()\n",
    "mean_tstep_summary_dict_20=Customdictionary()\n",
    "mean_tstep_summary_dict_25=Customdictionary()\n",
    "mean_tstep_summary_dict_30=Customdictionary()\n",
    "mean_tstep_summary_dict_40=Customdictionary()\n",
    "\n",
    "for key, value in heatmap_nonconverged_dict_00.items():\n",
    "    failed_experiments=len(value)\n",
    "    mean_tstep=np.mean(value)\n",
    "#     summary_dict_00[key]=successful_experiments,round(mean_tstep)\n",
    "    count_tstep_summary_dict_00[key]=failed_experiments\n",
    "    mean_tstep_summary_dict_00[key]=round(mean_tstep)\n",
    "    \n",
    "for key, value in heatmap_nonconverged_dict_05.items():\n",
    "    failed_experiments=len(value)\n",
    "    mean_tstep=np.mean(value)\n",
    "#     summary_dict_05[key]=successful_experiments,round(mean_tstep)\n",
    "    count_tstep_summary_dict_05[key]=failed_experiments\n",
    "    mean_tstep_summary_dict_05[key]=round(mean_tstep)\n",
    "\n",
    "for key, value in heatmap_nonconverged_dict_10.items():\n",
    "    failed_experiments=len(value)\n",
    "    mean_tstep=np.mean(value)\n",
    "#     summary_dict_10[key]=successful_experiments,round(mean_tstep)\n",
    "    count_tstep_summary_dict_10[key]=failed_experiments\n",
    "    mean_tstep_summary_dict_10[key]=round(mean_tstep)\n",
    "\n",
    "for key, value in heatmap_nonconverged_dict_20.items():\n",
    "    failed_experiments=len(value)\n",
    "    mean_tstep=np.mean(value)\n",
    "#     summary_dict_20[key]=successful_experiments,round(mean_tstep)\n",
    "    count_tstep_summary_dict_20[key]=failed_experiments\n",
    "    mean_tstep_summary_dict_20[key]=round(mean_tstep)\n",
    "\n",
    "for key, value in heatmap_nonconverged_dict_25.items():\n",
    "    failed_experiments=len(value)\n",
    "    mean_tstep=np.mean(value)\n",
    "#     summary_dict_25[key]=successful_experiments,round(mean_tstep)\n",
    "    count_tstep_summary_dict_25[key]=failed_experiments\n",
    "    mean_tstep_summary_dict_25[key]=round(mean_tstep)\n",
    "\n",
    "for key, value in heatmap_nonconverged_dict_30.items():\n",
    "    failed_experiments=len(value)\n",
    "    mean_tstep=np.mean(value)\n",
    "#     summary_dict_30[key]=successful_experiments,round(mean_tstep)\n",
    "    count_tstep_summary_dict_30[key]=failed_experiments\n",
    "    mean_tstep_summary_dict_30[key]=round(mean_tstep)\n",
    "\n",
    "for key, value in heatmap_nonconverged_dict_40.items():\n",
    "    failed_experiments=len(value)\n",
    "    mean_tstep=np.mean(value)\n",
    "#     summary_dict_40[key]=successful_experiments,round(mean_tstep)\n",
    "    count_tstep_summary_dict_40[key]=failed_experiments\n",
    "    mean_tstep_summary_dict_40[key]=round(mean_tstep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Count of failed experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to create an array from the summary dictionaries.\n",
    "index=['0.00']\n",
    "ct_df1=pd.DataFrame(data=count_tstep_summary_dict_00,index=index)\n",
    "index=['0.05']\n",
    "ct_df2=pd.DataFrame(data=count_tstep_summary_dict_05,index=index)\n",
    "index=['0.10']\n",
    "ct_df3=pd.DataFrame(data=count_tstep_summary_dict_10,index=index)\n",
    "index=['0.20']\n",
    "ct_df4=pd.DataFrame(data=count_tstep_summary_dict_20,index=index)\n",
    "index=['0.25']\n",
    "ct_df5=pd.DataFrame(data=count_tstep_summary_dict_25,index=index)\n",
    "index=['0.30']\n",
    "ct_df6=pd.DataFrame(data=count_tstep_summary_dict_30,index=index)\n",
    "index=['0.40']\n",
    "ct_df7=pd.DataFrame(data=count_tstep_summary_dict_40,index=index)\n",
    "\n",
    "ct_df_all=ct_df7.append(ct_df6).append(ct_df5).append(ct_df4).append(ct_df3).append(ct_df2).append(ct_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Mean timestep for failed experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to create an array from the summary dictionaries. Shoddy code\n",
    "index=['0.00']\n",
    "mt_df1=pd.DataFrame(data=mean_tstep_summary_dict_00,index=index)\n",
    "index=['0.05']\n",
    "mt_df2=pd.DataFrame(data=mean_tstep_summary_dict_05,index=index)\n",
    "index=['0.10']\n",
    "mt_df3=pd.DataFrame(data=mean_tstep_summary_dict_10,index=index)\n",
    "index=['0.20']\n",
    "mt_df4=pd.DataFrame(data=mean_tstep_summary_dict_20,index=index)\n",
    "index=['0.25']\n",
    "mt_df5=pd.DataFrame(data=mean_tstep_summary_dict_25,index=index)\n",
    "index=['0.30']\n",
    "mt_df6=pd.DataFrame(data=mean_tstep_summary_dict_30,index=index)\n",
    "index=['0.40']\n",
    "mt_df7=pd.DataFrame(data=mean_tstep_summary_dict_40,index=index)\n",
    "\n",
    "mt_df_all=mt_df7.append(mt_df6).append(mt_df5).append(mt_df4).append(mt_df3).append(mt_df2).append(mt_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary Creation for counts of failed robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "count_failedrobot_ratio_dict_00=Customdictionary()\n",
    "count_failedrobot_ratio_dict_05=Customdictionary()\n",
    "count_failedrobot_ratio_dict_10=Customdictionary()\n",
    "count_failedrobot_ratio_dict_20=Customdictionary()\n",
    "count_failedrobot_ratio_dict_25=Customdictionary()\n",
    "count_failedrobot_ratio_dict_30=Customdictionary()\n",
    "count_failedrobot_ratio_dict_40=Customdictionary()\n",
    "\n",
    "count_failedrobot_num_dict_00=Customdictionary()\n",
    "count_failedrobot_num_dict_05=Customdictionary()\n",
    "count_failedrobot_num_dict_10=Customdictionary()\n",
    "count_failedrobot_num_dict_20=Customdictionary()\n",
    "count_failedrobot_num_dict_25=Customdictionary()\n",
    "count_failedrobot_num_dict_30=Customdictionary()\n",
    "count_failedrobot_num_dict_40=Customdictionary()\n",
    "\n",
    "\n",
    "for key,value in countfailed_robots_failedexp.items(): # Value is the number of failed robots\n",
    "    fname=key.split(\"_\")\n",
    "    num_robots=int(remove_chars(fname[0]))\n",
    "    num_liars=int(remove_chars(fname[1]))\n",
    "    noise=float(remove_chars(fname[2]))\n",
    "    density=float(remove_chars(fname[3]))\n",
    "    num_working=num_robots-num_liars\n",
    "    ratio_working=float(num_working/num_robots)\n",
    "    \n",
    "    if (noise==0.0):\n",
    "        count_failedrobot_ratio_dict_00[ratio_working]=value\n",
    "        count_failedrobot_num_dict_00[num_working]=value\n",
    "    elif (noise==0.05):\n",
    "        count_failedrobot_ratio_dict_05[ratio_working]=value\n",
    "        count_failedrobot_num_dict_05[num_working]=value\n",
    "    elif (noise==0.10):\n",
    "        count_failedrobot_ratio_dict_10[ratio_working]=value\n",
    "        count_failedrobot_num_dict_10[num_working]=value\n",
    "    elif (noise==0.20):\n",
    "        count_failedrobot_ratio_dict_20[ratio_working]=value\n",
    "        count_failedrobot_num_dict_20[num_working]=value\n",
    "    elif (noise==0.25):\n",
    "        count_failedrobot_ratio_dict_25[ratio_working]=value\n",
    "        count_failedrobot_num_dict_25[num_working]=value\n",
    "    elif (noise==0.30):\n",
    "        count_failedrobot_ratio_dict_30[ratio_working]=value\n",
    "        count_failedrobot_num_dict_30[num_working]=value\n",
    "    elif (noise==0.40):\n",
    "        count_failedrobot_ratio_dict_40[ratio_working]=value\n",
    "        count_failedrobot_num_dict_40[num_working]=value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Count of failed robots vs. ratio of robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to create an array from the summary dictionaries.\n",
    "index=['0.00']\n",
    "ct_f1_ratio=pd.DataFrame(data=count_failedrobot_ratio_dict_00,index=index)\n",
    "index=['0.05']\n",
    "ct_f2_ratio=pd.DataFrame(data=count_failedrobot_ratio_dict_05,index=index)\n",
    "index=['0.10']\n",
    "ct_f3_ratio=pd.DataFrame(data=count_failedrobot_ratio_dict_10,index=index)\n",
    "index=['0.20']\n",
    "ct_f4_ratio=pd.DataFrame(data=count_failedrobot_ratio_dict_20,index=index)\n",
    "index_ratio=['0.25']\n",
    "ct_f5_ratio=pd.DataFrame(data=count_failedrobot_ratio_dict_25,index=index)\n",
    "index=['0.30']\n",
    "ct_f6_ratio=pd.DataFrame(data=count_failedrobot_ratio_dict_30,index=index)\n",
    "index=['0.40']\n",
    "ct_f7_ratio=pd.DataFrame(data=count_failedrobot_ratio_dict_40,index=index)\n",
    "\n",
    "ct_f_ratio_all=ct_f7_ratio.append(ct_f6_ratio).append(ct_f5_ratio).append(ct_f4_ratio).append(ct_f3_ratio).append(ct_f2_ratio).append(ct_f1_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_f_ratio_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Count of failed robots vs. number of working robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to create an array from the summary dictionaries. Shoddy code\n",
    "index=['0.00']\n",
    "ct_f1_num=pd.DataFrame(data=count_failedrobot_num_dict_00,index=index)\n",
    "index=['0.05']\n",
    "ct_f2_num=pd.DataFrame(data=count_failedrobot_num_dict_05,index=index)\n",
    "index=['0.10']\n",
    "ct_f3_num=pd.DataFrame(data=count_failedrobot_num_dict_10,index=index)\n",
    "index=['0.20']\n",
    "ct_f4_num=pd.DataFrame(data=count_failedrobot_num_dict_20,index=index)\n",
    "index=['0.25']\n",
    "ct_f5_num=pd.DataFrame(data=count_failedrobot_num_dict_25,index=index)\n",
    "index=['0.30']\n",
    "ct_f6_num=pd.DataFrame(data=count_failedrobot_num_dict_30,index=index)\n",
    "index=['0.40']\n",
    "ct_f7_num=pd.DataFrame(data=count_failedrobot_num_dict_40,index=index)\n",
    "\n",
    "ct_f_num_all=ct_f7_num.append(ct_f6_num).append(ct_f5_num).append(ct_f4_num).append(ct_f3_num).append(ct_f2_num).append(ct_f1_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_f_num_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Number of Failed Experiments [Sensor Noise vs. Defecting Ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(ct_df_all, annot=True,cmap='hot')\n",
    "plt.ylabel('Sensor Noise')\n",
    "plt.xlabel('Defecting Ratio')\n",
    "plt.title('Number of failed experiments')\n",
    "# plt.savefig(\"SuccessfulExperiments_Random\",bbox_inches='tight')\n",
    "# plt.savefig(\"SuccessfulExperiments_Defecting\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Timestep of Failed Experiments [Sensor Noise vs. Defecting Ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(mt_df_all, annot=True,cmap='summer')\n",
    "plt.ylabel('Sensor Noise')\n",
    "plt.xlabel('Defecting Ratio')\n",
    "plt.title('Mean Timestep for completion- Best Time')\n",
    "# plt.savefig(\"Successful_MeanTimesteps_Random\",bbox_inches='tight')\n",
    "# plt.savefig(\"Successful_MeanTimesteps_Defecting\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Number of Failed Robots [Sensor Noise vs. Defecting Ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(ct_f_ratio_all, annot=True,cmap='summer')\n",
    "plt.ylabel('Sensor Noise')\n",
    "plt.xlabel('Defecting Ratio')\n",
    "plt.title('Number of Failed Robots')\n",
    "# plt.savefig(\"Successful_MeanTimesteps_Random\",bbox_inches='tight')\n",
    "# plt.savefig(\"Successful_MeanTimesteps_Defecting\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Number of Failed Robots [Sensor Noise vs. Working Robots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(ct_f_num_all, annot=True,cmap='summer')\n",
    "plt.ylabel('Sensor Noise')\n",
    "plt.xlabel('Number of Working Robots')\n",
    "plt.title('MNumber of Failed Robots')\n",
    "# plt.savefig(\"Successful_MeanTimesteps_Random\",bbox_inches='tight')\n",
    "# plt.savefig(\"Successful_MeanTimesteps_Defecting\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scatter Plot of Messages Listened/Ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Successful experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries for message counts and final beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_messages_successfulexp={}\n",
    "scatter_beliefs_successfulexp={}\n",
    "\n",
    "for ind in range(len(successful_seeds)):\n",
    "    temp=successful_seeds[ind].split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    key_0=\"nrobots{}_nliars{}_noise{}_density{}\".format(num_robots,num_liars,noise,density)\n",
    "    key_1=\"seed{}\".format(seed)\n",
    "    \n",
    "    raw_data=pickle_dictionary[key_0][key_1]\n",
    "    raw_data=np.array(raw_data).reshape((num_working,9)) #From pickle dictionary\n",
    "        \n",
    "    timestep=raw_data[0,0]\n",
    "    correct_pattern_prob=raw_data[:,2]\n",
    "    total_received_messages=raw_data[:,4]\n",
    "    total_pruned_messages=raw_data[:,5]\n",
    "    total_lying_messages=raw_data[:,6]\n",
    "    total_lying_messages_believed=raw_data[:,7]\n",
    "    current_threshold=raw_data[:,8] \n",
    "\n",
    "    average_pattern_prob=np.mean(correct_pattern_prob)\n",
    "    average_sum_received=np.mean(total_received_messages)\n",
    "    average_sum_pruned=np.mean(total_pruned_messages)\n",
    "    average_sum_lying=np.mean(total_lying_messages)\n",
    "    average_sum_lying_believed=np.mean(total_lying_messages_believed)\n",
    "    average_threshold=np.mean(current_threshold)\n",
    "\n",
    "    key=\"_\".join((key_0,key_1))\n",
    "    for ind2 in range(num_working):\n",
    "        key_robot=\"_\".join((key,str(ind2))) # Creating a new key for every robot\n",
    "        messagesdata_robot=[total_received_messages[ind2],total_pruned_messages[ind2],\n",
    "                            total_lying_messages[ind2],total_lying_messages_believed[ind2]]\n",
    "        probthresholddata_robot=[correct_pattern_prob[ind2],current_threshold[ind2]]\n",
    "        \n",
    "        scatter_messages_successfulexp[key_robot]=messagesdata_robot\n",
    "        scatter_beliefs_successfulexp[key_robot]=probthresholddata_robot\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot messages vs. num. robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "# plt.xlim(1,10)\n",
    "\n",
    "for key,val in scatter_messages_successfulexp.items():\n",
    "    temp=key.split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    ratio_working=float(num_working/num_robots)\n",
    "    \n",
    "    # Total\n",
    "    recv_msg,pruned_msg,lying_msg,lying_msg_believed=val\n",
    "    \n",
    "    plt.scatter(num_working,recv_msg,c='blue',marker='o') # Total received messages blue circles\n",
    "    plt.scatter(num_working,pruned_msg,c='green',marker='o') # Total pruned messages green circles\n",
    "    plt.scatter(num_working,lying_msg,c='orange',marker='*') # Lying messages orange asterisks\n",
    "    plt.scatter(num_working,lying_msg_believed,c='red',marker='*') # Lying messages believed red asterisks\n",
    "    \n",
    "\n",
    "plt.ylabel('Message Count')\n",
    "plt.xlabel('Number of working robots')\n",
    "plt.title('Scatter plot of messages vs. robots successful experiments')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot messages vs. working robot ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "# plt.xlim(1,10)\n",
    "\n",
    "for key,val in scatter_messages_successfulexp.items():\n",
    "    temp=key.split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    ratio_working=float(num_working/num_robots)\n",
    "    \n",
    "    # Total\n",
    "    recv_msg,pruned_msg,lying_msg,lying_msg_believed=val\n",
    "    \n",
    "    plt.scatter(ratio_working,recv_msg,c='blue',marker='o') # Total received messages blue circles\n",
    "    plt.scatter(ratio_working,pruned_msg,c='green',marker='o') # Total pruned messages green circles\n",
    "    plt.scatter(ratio_working,lying_msg,c='orange',marker='*') # Lying messages orange asterisks\n",
    "    plt.scatter(ratio_working,lying_msg_believed,c='red',marker='*') # Lying messages believed red asterisks\n",
    "    \n",
    "\n",
    "plt.ylabel('Message Count')\n",
    "plt.xlabel('Ratio of working robots')\n",
    "plt.title('Scatter plot of messages vs. ratio of working robots successful experiments')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot beliefs vs. num. robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "# plt.xlim(1,10)\n",
    "\n",
    "for key,val in scatter_beliefs_successfulexp.items():\n",
    "    temp=key.split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    ratio_working=float(num_working/num_robots)\n",
    "    \n",
    "    # Total\n",
    "    correct_pattern_prob,current_threshold=val\n",
    "    \n",
    "    plt.scatter(num_working,correct_pattern_prob,c='green',marker='o') # Final belief probability green circle\n",
    "    plt.scatter(num_working,current_threshold,c='blue',marker='*') # Robot threshold blue asterisk\n",
    "    \n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Number of working robots')\n",
    "plt.title('Scatter plot of probability vs. robots successful experiments')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot beliefs vs. working robot ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "# plt.xlim(1,10)\n",
    "\n",
    "for key,val in scatter_beliefs_successfulexp.items():\n",
    "    temp=key.split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    ratio_working=float(num_working/num_robots)\n",
    "    \n",
    "    # Total\n",
    "    correct_pattern_prob,current_threshold=val\n",
    "    \n",
    "    plt.scatter(ratio_working,correct_pattern_prob,c='green',marker='o') # Final belief probability green circle\n",
    "    plt.scatter(ratio_working,current_threshold,c='blue',marker='*') # Robot threshold blue asterisk\n",
    "    \n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Ratio of working robots')\n",
    "plt.title('Scatter plot of probability vs. ratio of working robots successful experiments')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failed experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries for message counts and final beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_messages_failedexp={}\n",
    "scatter_beliefs_failedexp={}\n",
    "\n",
    "for ind in range(len(failed_seeds)):\n",
    "    temp=successful_seeds[ind].split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    key_0=\"nrobots{}_nliars{}_noise{}_density{}\".format(num_robots,num_liars,noise,density)\n",
    "    key_1=\"seed{}\".format(seed)\n",
    "    \n",
    "    raw_data=pickle_dictionary[key_0][key_1]\n",
    "    raw_data=np.array(raw_data).reshape((num_working,9)) #From pickle dictionary\n",
    "        \n",
    "    timestep=raw_data[0,0]\n",
    "    correct_pattern_prob=raw_data[:,2]\n",
    "    total_received_messages=raw_data[:,4]\n",
    "    total_pruned_messages=raw_data[:,5]\n",
    "    total_lying_messages=raw_data[:,6]\n",
    "    total_lying_messages_believed=raw_data[:,7]\n",
    "    current_threshold=raw_data[:,8] \n",
    "\n",
    "    average_pattern_prob=np.mean(correct_pattern_prob)\n",
    "    average_sum_received=np.mean(total_received_messages)\n",
    "    average_sum_pruned=np.mean(total_pruned_messages)\n",
    "    average_sum_lying=np.mean(total_lying_messages)\n",
    "    average_sum_lying_believed=np.mean(total_lying_messages_believed)\n",
    "    average_threshold=np.mean(current_threshold)\n",
    "\n",
    "    key=\"_\".join((key_0,key_1))\n",
    "    for ind2 in range(num_working):\n",
    "        key_robot=\"_\".join((key,str(ind2))) # Creating a new key for every robot\n",
    "        messagesdata_robot=[total_received_messages[ind2],total_pruned_messages[ind2],\n",
    "                            total_lying_messages[ind2],total_lying_messages_believed[ind2]]\n",
    "        probthresholddata_robot=[correct_pattern_prob[ind2],current_threshold[ind2]]\n",
    "        \n",
    "        scatter_messages_failedexp[key_robot]=messagesdata_robot\n",
    "        scatter_beliefs_failedexp[key_robot]=probthresholddata_robot\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot messages vs. num. robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "# plt.xlim(1,10)\n",
    "\n",
    "for key,val in scatter_messages_failedexp.items():\n",
    "    temp=key.split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    ratio_working=float(num_working/num_robots)\n",
    "    \n",
    "    # Total\n",
    "    recv_msg,pruned_msg,lying_msg,lying_msg_believed=val\n",
    "    \n",
    "    plt.scatter(num_working,recv_msg,c='blue',marker='o') # Total received messages blue circles\n",
    "    plt.scatter(num_working,pruned_msg,c='green',marker='o') # Total pruned messages green circles\n",
    "    plt.scatter(num_working,lying_msg,c='orange',marker='*') # Lying messages orange asterisks\n",
    "    plt.scatter(num_working,lying_msg_believed,c='red',marker='*') # Lying messages believed red asterisks\n",
    "    \n",
    "\n",
    "plt.ylabel('Message Count')\n",
    "plt.xlabel('Number of working robots')\n",
    "plt.title('Scatter plot of messages vs. robots failed experiments')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot messages vs. working robot ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "# plt.xlim(1,10)\n",
    "\n",
    "for key,val in scatter_messages_failedexp.items():\n",
    "    temp=key.split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    ratio_working=float(num_working/num_robots)\n",
    "    \n",
    "    # Total\n",
    "    recv_msg,pruned_msg,lying_msg,lying_msg_believed=val\n",
    "    \n",
    "    plt.scatter(ratio_working,recv_msg,c='blue',marker='o') # Total received messages blue circles\n",
    "    plt.scatter(ratio_working,pruned_msg,c='green',marker='o') # Total pruned messages green circles\n",
    "    plt.scatter(ratio_working,lying_msg,c='orange',marker='*') # Lying messages orange asterisks\n",
    "    plt.scatter(ratio_working,lying_msg_believed,c='red',marker='*') # Lying messages believed red asterisks\n",
    "    \n",
    "\n",
    "plt.ylabel('Message Count')\n",
    "plt.xlabel('Ratio of working robots')\n",
    "plt.title('Scatter plot of messages vs. ratio of working robots failed experiments')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot beliefs vs. num. robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "# plt.xlim(1,10)\n",
    "\n",
    "for key,val in scatter_beliefs_failedexp.items():\n",
    "    temp=key.split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    ratio_working=float(num_working/num_robots)\n",
    "    \n",
    "    # Total\n",
    "    correct_pattern_prob,current_threshold=val\n",
    "    \n",
    "    plt.scatter(num_working,correct_pattern_prob,c='green',marker='o') # Final belief probability green circle\n",
    "    plt.scatter(num_working,current_threshold,c='blue',marker='*') # Robot threshold blue asterisk\n",
    "    \n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Number of working robots')\n",
    "plt.title('Scatter plot of probability vs. robots failed experiments')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot beliefs vs. working robot ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15),dpi=100)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "# plt.xlim(1,10)\n",
    "\n",
    "for key,val in scatter_beliefs_failedexp.items():\n",
    "    temp=key.split(\"_\")\n",
    "    num_robots=int(remove_chars(temp[0]))\n",
    "    num_liars=int(remove_chars(temp[1]))\n",
    "    noise=float(remove_chars(temp[2]))\n",
    "    density=int(remove_chars(temp[3]))\n",
    "    seed=int(remove_chars(temp[4]))\n",
    "    num_working=num_robots-num_liars\n",
    "    ratio_working=float(num_working/num_robots)\n",
    "    \n",
    "    # Total\n",
    "    correct_pattern_prob,current_threshold=val\n",
    "    \n",
    "    plt.scatter(ratio_working,correct_pattern_prob,c='green',marker='o') # Final belief probability green circle\n",
    "    plt.scatter(ratio_working,current_threshold,c='blue',marker='*') # Robot threshold blue asterisk\n",
    "    \n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Ratio of working robots')\n",
    "plt.title('Scatter plot of probability vs. ratio of working robots failed experiments')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# BREAK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "325px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 626.85,
   "position": {
    "height": "40px",
    "left": "1153px",
    "right": "65px",
    "top": "241px",
    "width": "367px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
